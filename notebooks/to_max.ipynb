{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Application classes for data pipelines that are used in our trading apps.\"\"\"\n",
    "\n",
    "import datetime\n",
    "from functools import reduce\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.rrule import FR, MO, TH, TU, WE, WEEKLY, rrule\n",
    "from tradingdmp.data.prep_data import PrepData\n",
    "\n",
    "\n",
    "class DataIBPocReg():\n",
    "    \"\"\"Class used for fetching data with continues target for IB POC.\n",
    "\n",
    "    The data contains daily, quarterly and yearly data from bors-data.\n",
    "    The two options of target y are daily price percentage changes (from the\n",
    "    previous day closing price to the next day closing price) and the actual\n",
    "    daily price.\n",
    "    Features from daily, quarterly and yearly data exist as both percentage change and\n",
    "    actual values. Additionally sequence length can be selected for each feature type.\n",
    "    You can e.g. select 2 years of yearly report data, 4 quarters and 10 days.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mongodbkey: str):\n",
    "        \"\"\"Initializes PrepData instance for getting processed data.\"\"\"\n",
    "        self.pdata = PrepData(mongodbkey=mongodbkey)\n",
    "\n",
    "    def _check_inputs_type(\n",
    "        self,\n",
    "        ticker_list: List[str],\n",
    "        dt_start: datetime.datetime,\n",
    "        dt_end: datetime.datetime,\n",
    "    ) -> None:  # noqa: C901\n",
    "        \"\"\"Auxilary function to check that the input arguments have the correct type.\"\"\"\n",
    "        if not isinstance(ticker_list, list):\n",
    "            raise ValueError(\"ticker_list must be of type list.\")\n",
    "        if not isinstance(dt_start, datetime.datetime):\n",
    "            raise ValueError(\"dt_start must be of type datetime.\")\n",
    "        if not isinstance(dt_end, datetime.datetime):\n",
    "            raise ValueError(\"dt_end must be of type datetime.\")\n",
    "\n",
    "    def _check_data(self, df_x: pd.DataFrame) -> None:\n",
    "        \"\"\"Function to check that the data meets all our requirements.\"\"\"\n",
    "        # Check that there are no NaN or infinite values in df_x\n",
    "        # We only check df_x and not df_y because df_y can contain NaN because\n",
    "        # we do not have the price value of \"tomorrow\" and therefore cannot\n",
    "        # compute the price percentage changes for the last row of each ticker.\n",
    "        contains_nan = df_x.isin([np.nan]).any(axis=None)\n",
    "        if contains_nan:\n",
    "            raise ValueError(\"df_x contains NaN values.\")\n",
    "        contains_inf = df_x.isin([np.inf, -np.inf]).any(axis=None)\n",
    "        if contains_inf:\n",
    "            raise ValueError(\"df_x contains inf or -inf values.\")\n",
    "\n",
    "    def get_data(\n",
    "        self,\n",
    "        ticker_list: List[str],\n",
    "        dt_start: datetime.datetime,\n",
    "        dt_end: datetime.datetime,\n",
    "        history_len_daily: int = 10,\n",
    "        history_len_quarterly: int = 4,\n",
    "        history_len_yearly: int = 2,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Method for getting data that can be passed to a model.\n",
    "\n",
    "        This function fetches pre-processed data from bors-data, Yahoo and Finviz,\n",
    "        merges this data by day and ticker, conducts basic feature engineering,\n",
    "        constructs the target variable y and then returns the data for x and y.\n",
    "\n",
    "        Args:\n",
    "            ticker_list: A list of ticker symbols for which to get data.\n",
    "            dt_start: All data after incl. dt_start is fetched.\n",
    "            dt_end: All data until incl. dt_end is fetched.\n",
    "            history_len_daily: length of daily history sequence as features.\n",
    "            history_len_quarterly: length of quarterly history sequence as features.\n",
    "            history_len_yearly: length of yearly history sequence as features.\n",
    "\n",
    "        Returns:\n",
    "            complete_df: Return a Dataframe with all tickers training data.\n",
    "        \"\"\"\n",
    "        self._check_inputs_type(ticker_list, dt_start, dt_end)\n",
    "\n",
    "        data_daily = self.pdata.bors_data(\n",
    "            ticker_list=ticker_list,\n",
    "            dt_start=dt_start,\n",
    "            dt_end=dt_end,\n",
    "            granularity=\"daily\",\n",
    "        )\n",
    "\n",
    "        data_quarterly = self.pdata.bors_data(\n",
    "            ticker_list=ticker_list,\n",
    "            dt_start=dt_start,\n",
    "            dt_end=dt_end,\n",
    "            granularity=\"quarterly\",\n",
    "        )\n",
    "\n",
    "        data_yearly = self.pdata.bors_data(\n",
    "            ticker_list=ticker_list,\n",
    "            dt_start=dt_start,\n",
    "            dt_end=dt_end,\n",
    "            granularity=\"yearly\",\n",
    "        )\n",
    "\n",
    "        # Process each ticker\n",
    "        iter_count = 0\n",
    "        for ticker in ticker_list:\n",
    "\n",
    "            daily_iter = data_daily.loc[data_daily[\"ticker\"] == ticker]\n",
    "\n",
    "            quarterly_iter = data_quarterly.loc[data_quarterly[\"ticker\"] == ticker]\n",
    "\n",
    "            yearly_iter = data_yearly.loc[data_yearly[\"ticker\"] == ticker]\n",
    "\n",
    "            if (\n",
    "                (daily_iter.shape[0] == 0)\n",
    "                | (quarterly_iter.shape[0] == 0)\n",
    "                | (yearly_iter.shape[0] == 0)\n",
    "            ):\n",
    "                print(ticker, \"misses daily, quarterly or yearly\")\n",
    "                continue\n",
    "\n",
    "            daily_iter[\n",
    "                daily_iter.columns.difference([\"date\", \"ticker\"]) + \"_pct_change\"\n",
    "            ] = daily_iter[\n",
    "                daily_iter.columns.difference([\"date\", \"ticker\"])\n",
    "            ].pct_change()\n",
    "\n",
    "            quarterly_iter[\n",
    "                quarterly_iter.columns.difference([\"date\", \"ticker\"]) + \"_pct_change\"\n",
    "            ] = quarterly_iter[\n",
    "                quarterly_iter.columns.difference([\"date\", \"ticker\"])\n",
    "            ].pct_change()\n",
    "            yearly_iter[\n",
    "                yearly_iter.columns.difference([\"date\", \"ticker\"]) + \"_pct_change\"\n",
    "            ] = yearly_iter[\n",
    "                yearly_iter.columns.difference([\"date\", \"ticker\"])\n",
    "            ].pct_change()\n",
    "\n",
    "            # Processing daily data\n",
    "            # Convert to numpy array for simple reshaping\n",
    "            daily_iter_arr = np.array(daily_iter)\n",
    "\n",
    "            # Create numpy array with daily data features\n",
    "            # shape: (observations, (history_len_daily*features))\n",
    "            daily_feature_array = np.array(\n",
    "                [\n",
    "                    np.stack(daily_iter_arr)[iter : iter + history_len_daily]\n",
    "                    for iter in range(0, daily_iter.shape[0] - history_len_daily + 1)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Create report publication variable\n",
    "            # What date was the report actually reported not fiscal period it describes\n",
    "            quarterly_iter[\"report_pub_date\"] = quarterly_iter.date + pd.DateOffset(\n",
    "                months=3\n",
    "            )\n",
    "            yearly_iter[\"report_pub_date\"] = yearly_iter.date + pd.DateOffset(months=3)\n",
    "\n",
    "            # Creates the quarterly feature array, shape:\n",
    "            # (history_len_quarterly, quarter features, observations)\n",
    "            quarterly_feature_array = self._y_q_df_to_arr(\n",
    "                daily_feature_array, quarterly_iter, history_len_quarterly\n",
    "            )\n",
    "\n",
    "            # Creates the yearly feature array, shape:\n",
    "            # (history_len_yearly, yearly features, observations)\n",
    "            yearly_feature_array = self._y_q_df_to_arr(\n",
    "                daily_feature_array, yearly_iter, history_len_yearly\n",
    "            )\n",
    "\n",
    "            # Create transposed quarterly dataframe for each observation in the ticker\n",
    "            d_df_iter = self._array_to_df(\n",
    "                daily_feature_array, history_len_daily, \"daily\", daily_iter\n",
    "            )\n",
    "            q_df_iter = self._array_to_df(\n",
    "                quarterly_feature_array,\n",
    "                history_len_quarterly,\n",
    "                \"quarterly\",\n",
    "                quarterly_iter,\n",
    "            )\n",
    "\n",
    "            y_df_iter = self._array_to_df(\n",
    "                yearly_feature_array, history_len_yearly, \"yearly\", yearly_iter\n",
    "            )\n",
    "\n",
    "            daily_iter = daily_iter.iloc[\n",
    "                history_len_daily:,\n",
    "            ]\n",
    "            daily_iter.reset_index(drop=True, inplace=True)\n",
    "            d_df_iter.reset_index(drop=True, inplace=True)\n",
    "            q_df_iter.reset_index(drop=True, inplace=True)\n",
    "            y_df_iter.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            full_df_iter = pd.concat(\n",
    "                [\n",
    "                    d_df_iter,\n",
    "                    q_df_iter,\n",
    "                    y_df_iter,\n",
    "                    daily_iter[[\"date\", \"ticker\", \"Close\", \"Close_pct_change\"]],\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "            if iter_count == 0:\n",
    "                complete_df = full_df_iter\n",
    "            else:\n",
    "                # complete_df2 = full_df_iter\n",
    "                complete_df = pd.concat([complete_df, full_df_iter], join=\"inner\")\n",
    "\n",
    "            print(\"Finished processing ticker:\", ticker)\n",
    "            iter_count = +1\n",
    "\n",
    "        # Check data\n",
    "        # self._check_data(complete_df[complete_df.columns.difference(\n",
    "        #    [\"date\", \"ticker\", \"Close\"])])  # exclude y because it can have NA\n",
    "\n",
    "        complete_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return complete_df\n",
    "\n",
    "    def _array_to_df(\n",
    "        self, np_array: np.ndarray, seq_len: int, time_type: str, df: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Auxilary that converts numpy array to a transposed dataframe.\n",
    "\n",
    "        where each row match a day and column matching num_features*sequence length.\n",
    "        \"\"\"\n",
    "        if time_type == \"daily\":\n",
    "            np_array = np.moveaxis(np_array, [0, 1, 2], [2, 0, 1])\n",
    "\n",
    "        # Go through each row and create a new dataframe\n",
    "        for x in range(0, np_array.shape[2]):\n",
    "            temp_df = pd.DataFrame(data=np_array[:, :, x], columns=df.columns)\n",
    "            temp_df = temp_df[temp_df.columns.difference([\"ticker\"])]\n",
    "\n",
    "            # Rank each date for naming, e.g. yearly EBIT_yearly_1, EBIT_Yearly_2\n",
    "            if temp_df[\"date\"].values.dtype == \"<M8[ns]\":  # If al\n",
    "                temp_df[\"date\"] = (\n",
    "                    time_type\n",
    "                    + \"_\"\n",
    "                    + temp_df[\"date\"].rank(ascending=False).astype(int).astype(str)\n",
    "                )\n",
    "            # If not enough historical data, still create the columns but set to 0\n",
    "            else:\n",
    "                temp_df[\"date\"] = list(\n",
    "                    reversed(range(1, seq_len + 1))\n",
    "                )  # if missing data\n",
    "                temp_df[\"date\"] = time_type + \"_\" + temp_df[\"date\"].astype(str)\n",
    "\n",
    "            # Transpose so that we have each column being a historical value instead of\n",
    "            # each row\n",
    "            temp_df = temp_df.set_index([\"date\"]).unstack()\n",
    "            temp_df.index = pd.DataFrame(\n",
    "                index=[\"_\".join(map(str, i)) for i in temp_df.index.tolist()]\n",
    "            ).index\n",
    "            temp_df.index = (\n",
    "                temp_df.index.str.lower().str.replace(\"-\", \"_\").str.split(\" \").str[0]\n",
    "            )\n",
    "            temp_df = pd.DataFrame(temp_df).transpose()\n",
    "\n",
    "            # Add to main dataframe\n",
    "            if x == 0:\n",
    "                df_iter = temp_df\n",
    "            else:\n",
    "                df_iter = pd.concat([df_iter, temp_df], axis=0)\n",
    "        return df_iter\n",
    "\n",
    "    def _y_q_df_to_arr(\n",
    "        self, daily_feature_array: np.ndarray, df: pd.DataFrame, seq_len: int\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Auxilary function that matches quarterly and yearly dates to daily data.\n",
    "\n",
    "        You can only have quarterly/yearly data per day that has actually been reported.\n",
    "        Creates the quarterly feature array, shape: (seq_len, num_features, obs)\n",
    "        \"\"\"\n",
    "        # For each daily observation in dataset\n",
    "        iter_list = []\n",
    "        for x in range(0, daily_feature_array.shape[0]):\n",
    "            # If daily date is before quarterly report pub date set that observations\n",
    "            # filled with zeroes/skip\n",
    "            q_rows_match = df[\n",
    "                df[\"report_pub_date\"] <= daily_feature_array[x][-1][0]\n",
    "            ].index\n",
    "            if len(q_rows_match) < seq_len:\n",
    "                feature_array = np.zeros((seq_len, df.shape[1]))\n",
    "            # Add the last seq_len quarters of data to feature array\n",
    "            else:\n",
    "                feature_array = np.array(df.loc[q_rows_match].tail(seq_len))\n",
    "\n",
    "            iter_list.append(feature_array)\n",
    "        feature_array = np.dstack(iter_list)\n",
    "        return feature_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aac92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nordic_large = [\n",
    "    # crashes \"8TRA\", \"CINT\",\"BEIJ B\", \"FPAR PREF\", \"JM\",\"KNEBV\", \"KOJAMO\",\"LUND B\",\"RILBA\",\"SEB A\", \"SEB C\", \"TIETO\",\"TIETOS\",\n",
    "\n",
    "    \"AAK\", \"ABB\", \"ADDT B\", \"AF B\", \"ALFA\", \"ALIV SDB\", \"ALK B\",\n",
    "    \"ALMB\", \"AM1\", \"AM1S\", \"AMBU B\", \"ARION SDB\", \"ARJO B\", \"ASSA B\",\n",
    "    \"ATCO B\", \"ATRLJ B\", \"AXFO\", \"AZA\", \"AZN\", \"BALD B\",\n",
    "\n",
    "    \"BETS B\",\n",
    "    \"BHG\", \"BILL\", \"BOL\", \"BRAV\", \"BURE\",  \"CARL B\", \"CAST\", \"CATE\",\n",
    "    \"CGCBV\", \"CHR\",\n",
    "    \"COLO B\", \"CTY1S\", \"DANSKE\", \"DEMANT\", \"DFDS\",\n",
    "    \"DOM\", \"DRLCO\", \"DSV\", \"EKTA B\", \"ELISA\",  \"ELUX B\",\n",
    "    \"EPI B\", \"EPRO B\", \"EQT\",  \"ERIC B\",  \"ESSITY B\",\n",
    "    \"EVO\", \"FABG\", \"FLS\", \"FOI B\", \"FORTUM\", \"FPAR D\",\n",
    "\n",
    "    \"FSKRS\", \"G4S\", \"GETI B\", \"GMAB\", \"GN\", \"HEXA B\", \"HM B\",\n",
    "    \"HOLM B\", \"HPOL B\", \"HUFV A\", \"HUH1V\",  \"HUSQ B\", \"ICA\", \"INDT\",\n",
    "    \"INDU C\", \"INTRUM\",  \"INVE B\", \"ISS\", \"JDAN\",\n",
    "\n",
    "    \"JYSK\", \"KBHL\", \"KCR\", \"KEMIRA\", \"KESKOA\", \"KESKOB\", \"KIND SDB\",\n",
    "    \"KINV B\", \"KLED\",  \"KLOV B\", \"KLOV PREF\",\n",
    "\n",
    "\n",
    "    \"LATO B\", \"LIFCO B\", \"LOOMIS\", \"LUMI\", \"LUN\",\n",
    "    \"LUNE\",\n",
    "    \"MAERSK B\", \"MCOV B\", \"METSA\", \"METSB\", \"MOCORP\", \"MYCR\",  \"NCC B\",\n",
    "    \"NDA DK\", \"NDA FI\", \"NDA SE\", \"NELES\", \"NENT B\", \"NESTE\", \"NETC\",\n",
    "    \"NIBE B\", \"NOBI\", \"NOKIA\", \"NOLA B\", \"NOVO B\", \"NYF\", \"NZYM B\", \"ORNAV\",\n",
    "    \"ORNBV\", \"ORSTED\", \"OSSR\", \"OUT1V\", \"PEAB B\", \"PLAZ B\", \"PNDORA\", \"PNDX B\",\n",
    "    \"RATO B\", \"RBREW\", \"RESURS\",\n",
    "\n",
    "    \"ROCK B\",\n",
    "    \"SAA1V\", \"SAAB B\",  \"SAGA B\", \"SAGA D\", \"SAMPO\", \"SAND\", \"SAVE\",\n",
    "    \"SBB B\", \"SBB D\",  \"SCA B\", \"SCHO\",\n",
    "    \"SECT B\",\n",
    "    \"SECU B\",  \"SHB B\", \"SIM\", \"SINCH\", \"SKA B\",  \"SKF B\",\n",
    "    \"SOBI\", \"SPNO\", \"SSAB B\", \"SSABAH\", \"SSABBH\",  \"STE R\",\n",
    "    \"STEAV\", \"STERV\", \"STG\", \"SWEC B\", \"SWED A\", \"SWMA\", \"SYDB\",\n",
    "    \"TEL2 B\", \"TELIA\", \"TELIA1\", \"THULE\",\n",
    "\n",
    "    \"TIGO SDB\", \"TOP\", \"TREL B\", \"TRYG\", \"TTALO\", \"TYRES\", \"UPM\", \"VALMT\",\n",
    "    \"VITR\", \"VNE SDB\", \"VOLV B\", \"VWS\", \"WALL B\", \"WIHL\", \"WRT1V\",\n",
    "    \"YIT\", \"ZEAL\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# , \"AAK\", \"EVO\", \"HM B\"]\n",
    "symbols = [\"ABB\"]#, \"HM B\", \"AAB\", \"ASSA B\", \"EVO\", \"AXA\", \"BALCO\", \"PNDX B\", \"SAGA\", \"VOLV B\"]\n",
    "mongodbkey = \"\"\n",
    "data_fetcher = DataIBPocReg(mongodbkey)\n",
    "\n",
    "complete_df = data_fetcher.get_data(\n",
    "    ticker_list=nordic_large,\n",
    "    dt_start=datetime.datetime(2017, 1, 1),\n",
    "    dt_end=datetime.datetime(2021, 4, 15))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
